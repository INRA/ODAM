{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ODAM: Deployment and User's Guide # ODAM (Open Data for Access and Mining) is an Experiment Data Table Management System (EDTMS) ODAM (Open Data for Access and Mining) is an Experimental Data Table Management System (EDTMS) that implements a simple and effective way to make research data widely accessible and fully available for reuse, and this with minimal effort on the part of the data provider, and allows any scientist or data researcher to be able to explore the dataset and then extract some or all of the data according to their needs. For full documentation read the ODAM - Deployment and User's Guide","title":"Home"},{"location":"#odam-deployment-and-users-guide","text":"ODAM (Open Data for Access and Mining) is an Experiment Data Table Management System (EDTMS) ODAM (Open Data for Access and Mining) is an Experimental Data Table Management System (EDTMS) that implements a simple and effective way to make research data widely accessible and fully available for reuse, and this with minimal effort on the part of the data provider, and allows any scientist or data researcher to be able to explore the dataset and then extract some or all of the data according to their needs. For full documentation read the ODAM - Deployment and User's Guide","title":"ODAM: Deployment and User's Guide"},{"location":"about/","text":"ODAM: Deployment and User's Guide # (C) Daniel Jacob - INRAE UMR 1332 BFP, PMB - 2020 - Version 1.1 Set of tools and protocols implemented in this work Description Type Link Data Preparation Protocol for ODAM Compliance Documentation doi:10.17504/protocols.io.betcjeiw API Documentation based on Swagger Web API Tool INRA-PMB/ODAM/1.0.1-oas3/ R ODAM package and How to use it Package https://cran.r-project.org/package=Rodam R ODAM package Vignette Package Rodam/vignettes/Rodam.html Virtual Machine embedding the ODAM software on Oracle VM VirtualBox along with its installation guide Virtual Machine + Documentation https://doi.org/10.15454/C9LAEF Docker containers on DockerHub for installing on a Linux machine Container https://hub.docker.com/r/odam/getdata/ https://hub.docker.com/r/odam/dataexplorer/ A very lightweight local web server for Windows to deploy the ODAM API Web API Tool http://pmb-bordeaux.fr/odam/ODAMwebserver/ Examples of Jupyter notebooks (R & Python) based on the ODAM Web API Notebook https://github.com/djacob65/binder_odam https://doi.org/10.24433/CO.8981049.v1 https://doi.org/10.24433/CO.0011270.v1 Modeling the growth of tomato fruits based on enzyme activity profiles (Example of data analysis interfaced by ODAM) Notebook https://hal.inrae.fr/hal-02611223 ODAM Source code on GitHub Source Code https://github.com/inrae/ODAM JSON Schema for ODAM data package Source Code https://github.com/djacob65/odam-datapackage/","title":"About"},{"location":"about/#odam-deployment-and-users-guide","text":"(C) Daniel Jacob - INRAE UMR 1332 BFP, PMB - 2020 - Version 1.1 Set of tools and protocols implemented in this work Description Type Link Data Preparation Protocol for ODAM Compliance Documentation doi:10.17504/protocols.io.betcjeiw API Documentation based on Swagger Web API Tool INRA-PMB/ODAM/1.0.1-oas3/ R ODAM package and How to use it Package https://cran.r-project.org/package=Rodam R ODAM package Vignette Package Rodam/vignettes/Rodam.html Virtual Machine embedding the ODAM software on Oracle VM VirtualBox along with its installation guide Virtual Machine + Documentation https://doi.org/10.15454/C9LAEF Docker containers on DockerHub for installing on a Linux machine Container https://hub.docker.com/r/odam/getdata/ https://hub.docker.com/r/odam/dataexplorer/ A very lightweight local web server for Windows to deploy the ODAM API Web API Tool http://pmb-bordeaux.fr/odam/ODAMwebserver/ Examples of Jupyter notebooks (R & Python) based on the ODAM Web API Notebook https://github.com/djacob65/binder_odam https://doi.org/10.24433/CO.8981049.v1 https://doi.org/10.24433/CO.0011270.v1 Modeling the growth of tomato fruits based on enzyme activity profiles (Example of data analysis interfaced by ODAM) Notebook https://hal.inrae.fr/hal-02611223 ODAM Source code on GitHub Source Code https://github.com/inrae/ODAM JSON Schema for ODAM data package Source Code https://github.com/djacob65/odam-datapackage/","title":"ODAM: Deployment and User's Guide"},{"location":"api/","text":"ODAM: Deployment and User's Guide # Web API # Based on REST services using a Resource Naming convention: an understandable resource naming leading to an easily leveraged Web service API (Identification/querying of resources) and easy to implement within R. Output formats: TSV, JSON and XML. Even if the WS outputs are not dedicated to human readers (the script languages as R are the typical clients), the XML outputs can be human readable in a web browser, made possible by using a XSL transformation mechanism which converts the XML outputs to HTML format. Using the two metadata files, it is possible to build a tree structure from which the data files can be queried to extract a subset. The tree structure is built on the Entity-Attribute-Value scheme. Field Description Examples <data format> Format of the retrieved data; possible values are: 'xml', \u2018json\u2019 or \u2018tsv' tsv <dataset name> Short name (tag) of your dataset frim1 <subset> Short name of a data subset samples <entry> Name of an attribute entry (defined by the user in the a_attribute file (column \u2018entry\u2019) sampleid <category> Name of the attribute category; (assigned by the user in the a_attribute file (column \u2018category\u2019). Possible values are: \u2018identifier\u2019, \u2018factor\u2019, \u2018qualitative\u2019, \u2018quantitative\u2019 quantitative (<subset>) Set of data subsets by merging all the subsets with lower rank than the specified subset and following the pathway defined by the \"is_part_of\" links. (samples) <=> plants + samples <value> Exact value of the desired entry or category 1 (for subset) or Factor (for category) API Documentation on SwaggerHub : INRA-PMB/ODAM/1.0.1-oas3","title":"Web Services"},{"location":"api/#odam-deployment-and-users-guide","text":"","title":"ODAM: Deployment and User's Guide"},{"location":"api/#web-api","text":"Based on REST services using a Resource Naming convention: an understandable resource naming leading to an easily leveraged Web service API (Identification/querying of resources) and easy to implement within R. Output formats: TSV, JSON and XML. Even if the WS outputs are not dedicated to human readers (the script languages as R are the typical clients), the XML outputs can be human readable in a web browser, made possible by using a XSL transformation mechanism which converts the XML outputs to HTML format. Using the two metadata files, it is possible to build a tree structure from which the data files can be queried to extract a subset. The tree structure is built on the Entity-Attribute-Value scheme. Field Description Examples <data format> Format of the retrieved data; possible values are: 'xml', \u2018json\u2019 or \u2018tsv' tsv <dataset name> Short name (tag) of your dataset frim1 <subset> Short name of a data subset samples <entry> Name of an attribute entry (defined by the user in the a_attribute file (column \u2018entry\u2019) sampleid <category> Name of the attribute category; (assigned by the user in the a_attribute file (column \u2018category\u2019). Possible values are: \u2018identifier\u2019, \u2018factor\u2019, \u2018qualitative\u2019, \u2018quantitative\u2019 quantitative (<subset>) Set of data subsets by merging all the subsets with lower rank than the specified subset and following the pathway defined by the \"is_part_of\" links. (samples) <=> plants + samples <value> Exact value of the desired entry or category 1 (for subset) or Factor (for category) API Documentation on SwaggerHub : INRA-PMB/ODAM/1.0.1-oas3","title":"Web API"},{"location":"data_explorer/","text":"ODAM: Deployment and User's Guide # Data Explorer # The Data Explorer makes data easy to explore, visualize, and subsequently to better understand the data as a whole. Explore your data in several ways according to your concerns by interacting with the graphs. For instance, univariate, bivariate and multivariate approaches have been implemented so that they are very easy to be interactively used. This is very useful in order to have a first glimpse of the data that can show trends and this allows the data to be well characterized, which is necessary to then choose how to analyze it later on. The Data Explorer Example of graphical output produced by the Data Explorer For each analysis, several possibilities can be explored by selecting many parameters and interacting with the graphs. Graphics can be easily exported as PNG files. An interesting possibility is that you can make a selection of a subset of data and then export it directly into your spreadsheet. Export a previously selected data subset.","title":"Data Explorer"},{"location":"data_explorer/#odam-deployment-and-users-guide","text":"","title":"ODAM: Deployment and User's Guide"},{"location":"data_explorer/#data-explorer","text":"The Data Explorer makes data easy to explore, visualize, and subsequently to better understand the data as a whole. Explore your data in several ways according to your concerns by interacting with the graphs. For instance, univariate, bivariate and multivariate approaches have been implemented so that they are very easy to be interactively used. This is very useful in order to have a first glimpse of the data that can show trends and this allows the data to be well characterized, which is necessary to then choose how to analyze it later on. The Data Explorer Example of graphical output produced by the Data Explorer For each analysis, several possibilities can be explored by selecting many parameters and interacting with the graphs. Graphics can be easily exported as PNG files. An interesting possibility is that you can make a selection of a subset of data and then export it directly into your spreadsheet. Export a previously selected data subset.","title":"Data Explorer"},{"location":"data_type/","text":"ODAM: Deployment and User's Guide # Data collection and preparation # Data Type # Whatever the kind of experiment, this assumes a design of experiment ( DoE ) involving individuals, samples or whatever things, as the main objects of study and producing several experimental data tables . This also assumes the observation of dependent variables resulting from effects of some controlled independent variables (factors). Moreover, the objects of study usually have an identifier for each of them, and the variables can be quantitative or qualitative. Example of an experiment data table viewed according to the repartition by category as introduced in the text Data management : promote good practices # First and foremost, it is important to have well-organized data. The files generated during data collection have to be organized according to the entity-attribute relational model. Indeed, each entity corresponds to a type of collected data (samples, compounds, ...) for which is associated a set of attributes, i.e. observed or measured variables. Well organized data means that each variable forms a column, each observation forms a line, and each type of \"unit observational\" forms a table, i.e a file. Then, a link is established for each subset with the subset from which it was obtained, so that the links can be interpreted as \"obtained from\", since each column of each subset of data must be associated with a type of experimental data (called a category), especially those corresponding to identifiers that the links are based on. A link is established for each subset with the subset from which it was obtained, so that the links can be interpreted as \"obtained from\", since each column of each subset of data must be associated with a type of experimental data (called a category), especially those corresponding to identifiers that the links are based on. Another good practice is to promote non-proprietary formats such as TSV , which is a necessary and indispensable step towards \"open linked data\" ( 5 gold stars principle). So an ODAM dataset is a bundle that contains a set of TSV files. The TSV files are simple tables containing the data of the dataset. All steps concerning the collection and preparation of data have been published and are available online at protocols.io Data Preparation Protocol for ODAM Compliance. protocols.io https://dx.doi.org/10.17504/protocols.io.betcjeiw The purpose of this protocol is to describe all the steps involved in collecting, preparing and annotating the data from an experiment associated with an experimental design (DoE) that will then allow the user to benefit from the services offered by ODAM. The overall approach is based on good data management practices concerning data structuring and the description of structural metadata. Indeed, ODAM allows to put metadata in depth, i.e. at the level of the data itself (i.e. metadata at column-level such as factors, variables,...) and not only as a \"hat\" on the data set. Thus, having the actual data elements also machine-readable makes the dataset of a higher level of interoperability and makes functional interlinking and analysis in broader context much easier.","title":"Data Type"},{"location":"data_type/#odam-deployment-and-users-guide","text":"","title":"ODAM: Deployment and User's Guide"},{"location":"data_type/#data-collection-and-preparation","text":"","title":"Data collection and preparation"},{"location":"data_type/#data-type","text":"Whatever the kind of experiment, this assumes a design of experiment ( DoE ) involving individuals, samples or whatever things, as the main objects of study and producing several experimental data tables . This also assumes the observation of dependent variables resulting from effects of some controlled independent variables (factors). Moreover, the objects of study usually have an identifier for each of them, and the variables can be quantitative or qualitative. Example of an experiment data table viewed according to the repartition by category as introduced in the text","title":"Data Type"},{"location":"data_type/#data-management-promote-good-practices","text":"First and foremost, it is important to have well-organized data. The files generated during data collection have to be organized according to the entity-attribute relational model. Indeed, each entity corresponds to a type of collected data (samples, compounds, ...) for which is associated a set of attributes, i.e. observed or measured variables. Well organized data means that each variable forms a column, each observation forms a line, and each type of \"unit observational\" forms a table, i.e a file. Then, a link is established for each subset with the subset from which it was obtained, so that the links can be interpreted as \"obtained from\", since each column of each subset of data must be associated with a type of experimental data (called a category), especially those corresponding to identifiers that the links are based on. A link is established for each subset with the subset from which it was obtained, so that the links can be interpreted as \"obtained from\", since each column of each subset of data must be associated with a type of experimental data (called a category), especially those corresponding to identifiers that the links are based on. Another good practice is to promote non-proprietary formats such as TSV , which is a necessary and indispensable step towards \"open linked data\" ( 5 gold stars principle). So an ODAM dataset is a bundle that contains a set of TSV files. The TSV files are simple tables containing the data of the dataset. All steps concerning the collection and preparation of data have been published and are available online at protocols.io Data Preparation Protocol for ODAM Compliance. protocols.io https://dx.doi.org/10.17504/protocols.io.betcjeiw The purpose of this protocol is to describe all the steps involved in collecting, preparing and annotating the data from an experiment associated with an experimental design (DoE) that will then allow the user to benefit from the services offered by ODAM. The overall approach is based on good data management practices concerning data structuring and the description of structural metadata. Indeed, ODAM allows to put metadata in depth, i.e. at the level of the data itself (i.e. metadata at column-level such as factors, variables,...) and not only as a \"hat\" on the data set. Thus, having the actual data elements also machine-readable makes the dataset of a higher level of interoperability and makes functional interlinking and analysis in broader context much easier.","title":"Data management : promote good practices"},{"location":"dataset_example/","text":"ODAM: Deployment and User's Guide # A dataset example # Fruit Integrative Modelling, an ERASysBio+ project : Yves Gibon (Coordinator) The project aimed to build a virtual tomato fruit that enables the prediction of metabolite levels given genetic and environmental inputs, by an iterative process between laboratories which combine expertise in fruit biology, ecophysiology, theoretical and experimental biochemistry, and biotechnology. To build a kinetic model encompassing the routes carbon takes, once imported into the fruit cells from the source organs of the mother plant. To integrate the kinetic model with a phenomenological model predicting sugar and organic acid contents as functions of time, light intensity, temperature and water availability. To obtain large-scale experimental measures of the consequences of altered environmental conditions. To assess the influence of the environment on fruit metabolism, tomato ( Solanum lycopersicum 'Moneymaker' ) plants were grown under contrasting conditions (optimal for commercial, shaded production) and locations. Samples were harvested at nine stages of development, and 36 enzyme activities of central metabolism were measured as well as protein, starch, and major metabolites, such as hexoses, sucrose, organic acids, and amino acids. About 580 tomato plants were grown in a greenhouse in the southwest of France ( Sainte-Livrade sur Lot ) during the summer of 2010 according to usual production practices. Links related to the dataset # Description Link Data explorer (*) https://pmb-bordeaux.fr/dataexplorer/?ds=frim1 Dataverse (*) https://doi.org/10.15454/95JUTK Jupyter notebooks (R & Python) https://nbviewer.jupyter.org/github/djacob65/binder_odam/tree/master/ Modeling the growth of tomato fruits based on enzyme activity profiles : An example of data analysis interfaced by ODAM https://hal.inrae.fr/hal-02611223 (*) Both repositories are supported by INRAE (France) for a minimum period of 10 years (until 2030). Publication of the dataset according to FAIR principles # Because ODAM is primarily an Experimental Data Table Management System (EDTMS) for data sharing, it must be associated with a suitable data repository in order to support data publishing. So the ODAM approach has to be regarded as complementary with publication of the data online within an institutional data repository as described in re3data.org (e.g. INRAE Data Portal ) associated or not with a scientific paper. To be compliant with the FAIR principles , not all data, documents, workflows and other tools need to be located in a single system, but from a central repository, it is the set of links that constitutes the true information management system. It must be able to be traversed by a human being as well as by machines. Data INRAE repository as a hub (based on Dataverse) allows to interconnect the different elements of the FRIM dataset. By relying on explicit schemas ( JSON-LD , JSON Schema ) for both metadata and data, it becomes possible to reuse the data without friction, both by humans and machines. Indeed an explicit schema allows to define structural metadata along with unambiguous definitions of all internal elements (e.g. column definitions, units of measurement), through links to accessible (standard) definitions. Moreover, this will result in better annotated and more easily usable data that meets effortlessly the FAIR criteria for reusability. Concerning the FAIRification of data, this has a positive impact on the FAIR criteria 'Interoperable' and 'Reusable', encouraging structured data using a discoverable, community-endorsed schema or data model. See also for more details: FAIR grids applied on FRIM dataset ODAM data-package based on JSON-Schema References # Biais B, B\u00e9nard C, Beauvoit B, Colombi\u00e9 S, Prodhomme D, M\u00e9nard G, Bernillon S, Gehl B, Gautier H, Ballias P, Mazat J-P, Sweetlove L, G\u00e9nard M, Gibon Y. 2014. Remarkable reproducibility of enzyme activity profiles in tomato fruits grown under contrasting environments provides a roadmap for studies of fruit metabolism. Plant Physiology 164, 1204-1221. doi: 10.1104/pp.113.231241","title":"Dataset example"},{"location":"dataset_example/#odam-deployment-and-users-guide","text":"","title":"ODAM: Deployment and User's Guide"},{"location":"dataset_example/#a-dataset-example","text":"Fruit Integrative Modelling, an ERASysBio+ project : Yves Gibon (Coordinator) The project aimed to build a virtual tomato fruit that enables the prediction of metabolite levels given genetic and environmental inputs, by an iterative process between laboratories which combine expertise in fruit biology, ecophysiology, theoretical and experimental biochemistry, and biotechnology. To build a kinetic model encompassing the routes carbon takes, once imported into the fruit cells from the source organs of the mother plant. To integrate the kinetic model with a phenomenological model predicting sugar and organic acid contents as functions of time, light intensity, temperature and water availability. To obtain large-scale experimental measures of the consequences of altered environmental conditions. To assess the influence of the environment on fruit metabolism, tomato ( Solanum lycopersicum 'Moneymaker' ) plants were grown under contrasting conditions (optimal for commercial, shaded production) and locations. Samples were harvested at nine stages of development, and 36 enzyme activities of central metabolism were measured as well as protein, starch, and major metabolites, such as hexoses, sucrose, organic acids, and amino acids. About 580 tomato plants were grown in a greenhouse in the southwest of France ( Sainte-Livrade sur Lot ) during the summer of 2010 according to usual production practices.","title":"A dataset example"},{"location":"dataset_example/#links-related-to-the-dataset","text":"Description Link Data explorer (*) https://pmb-bordeaux.fr/dataexplorer/?ds=frim1 Dataverse (*) https://doi.org/10.15454/95JUTK Jupyter notebooks (R & Python) https://nbviewer.jupyter.org/github/djacob65/binder_odam/tree/master/ Modeling the growth of tomato fruits based on enzyme activity profiles : An example of data analysis interfaced by ODAM https://hal.inrae.fr/hal-02611223 (*) Both repositories are supported by INRAE (France) for a minimum period of 10 years (until 2030).","title":"Links related to the dataset"},{"location":"dataset_example/#publication-of-the-dataset-according-to-fair-principles","text":"Because ODAM is primarily an Experimental Data Table Management System (EDTMS) for data sharing, it must be associated with a suitable data repository in order to support data publishing. So the ODAM approach has to be regarded as complementary with publication of the data online within an institutional data repository as described in re3data.org (e.g. INRAE Data Portal ) associated or not with a scientific paper. To be compliant with the FAIR principles , not all data, documents, workflows and other tools need to be located in a single system, but from a central repository, it is the set of links that constitutes the true information management system. It must be able to be traversed by a human being as well as by machines. Data INRAE repository as a hub (based on Dataverse) allows to interconnect the different elements of the FRIM dataset. By relying on explicit schemas ( JSON-LD , JSON Schema ) for both metadata and data, it becomes possible to reuse the data without friction, both by humans and machines. Indeed an explicit schema allows to define structural metadata along with unambiguous definitions of all internal elements (e.g. column definitions, units of measurement), through links to accessible (standard) definitions. Moreover, this will result in better annotated and more easily usable data that meets effortlessly the FAIR criteria for reusability. Concerning the FAIRification of data, this has a positive impact on the FAIR criteria 'Interoperable' and 'Reusable', encouraging structured data using a discoverable, community-endorsed schema or data model. See also for more details: FAIR grids applied on FRIM dataset ODAM data-package based on JSON-Schema","title":"Publication of the dataset according to FAIR principles"},{"location":"dataset_example/#references","text":"Biais B, B\u00e9nard C, Beauvoit B, Colombi\u00e9 S, Prodhomme D, M\u00e9nard G, Bernillon S, Gehl B, Gautier H, Ballias P, Mazat J-P, Sweetlove L, G\u00e9nard M, Gibon Y. 2014. Remarkable reproducibility of enzyme activity profiles in tomato fruits grown under contrasting environments provides a roadmap for studies of fruit metabolism. Plant Physiology 164, 1204-1221. doi: 10.1104/pp.113.231241","title":"References"},{"location":"getting_started/","text":"ODAM: Deployment and User's Guide # ODAM (Open Data for Access and Mining) is an Experiment Data Table Management System (EDTMS) Background # When generating data in an experiment involving several types of data from several analytical techniques, and this for the same samples, the task of being able to easily link these different data on the basis of sample identifiers is crucial. This is because the consistency of the data must be ensured throughout the experiment, so that it becomes unnecessary for each member to conduct a laborious investigation to find out who has the correct identifiers. Each time we plan to share data coming from a common experimental design, the classical challenges for fast using data by every partner are data storage and data access. We propose an approach for sharing project data all along its development phase, from the setup of the experimental schema up to the data acquisition from the various analyzes of samples, so that all data is readily available as soon as they are generated. Proposed solution # ODAM software is designed to manage experimental data tables in a quick and easy way for users. There is no need to develop a complex data model. Just complete the data with some structural metadata. These structural metadata will be used first to make full use of the data as soon as they are produced and formatted and then to annotate the dataset for later dissemination, either to project partners or more widely. The core idea in one shot The central idea which has been the founding idea of ODAM, is that data producers \"just\" have to drag and drop their data tables onto a storage space, which depending on the chosen infrastructure can be local (i.e. their PC, or a NAS) or remote (virtual disk space). So simply dropping data files (along with two additional metadata files) on the storage space allows users to access them through web services. This means there is no need for additional configuration on the server. ODAM proposes to meet certain needs typically encountered during the implementation of an experimental design in life science including several different analyses of the same sample. 1 - Data collecting and preparation The formatting of all the data and matching the data from the different analyses with their experimental context can be a long step. Tasks such as collecting and preparing data in order to combine several data sources require a lot of long, repetitive and tedious manipulations. Similarly, when modeling, subsets must be selected and then many scenarios with different parameters must be tested. 2 - Data sharing Enabling centralized management of identifiers (e.g. plants, crops, samples, etc.) so that they are unique and shared by all project members. Indeed, as each biological sample is most often aliquoted and then sent for analysis by different techniques, the data returned in tabular form must be able to be linked to the other data according to the identifiers of the samples Giving access to data for rapid use by each project member and this throughout the development phase, from the implementation of the experimental design to the acquisition of data from the various sample analyses, so that all data are readily available as soon as they are generated. 3 - Data publishing To be able to publish one's data without a colossal effort of formatting, and without the need for data archaeology. To be able to publish one's data according to the FAIR principles , at least the essentials To facilitate the reuse of data by providing structural metadata, thus avoiding that data consumers spend a disproportionate amount of time trying to understand the digital resources they need and devising specific ways to combine them. ODAM sofware suite allows experimental data tables to be widely accessible and fully reusable and this with minimal effort on the part of the data provider. Easily structure your data by adding structural metadata so that you can first exploit it locally yourself, before sharing it more widely just as easily. make research data locally or broadly accessible all along the project allow data to be selected then, downloadable by web API allow data and analysis to be visualized online Based on the following criteria: Centrally manage identifiers (plants, harvests, samples, ...) so that they are unique and shared by all Avoid the implementation of a complex data management system (requiring a data model) given that many changes can occur during the project. (possibility of new analysis, new measures or give up some others, ...) Facilitates the subsequent publication of data: either the data can serve to fill in an existing database or the data can be broadcast through a web-service approach with the associated metadata. For this work, we made the choice to keep the good old way of scientist to use worksheets, thus using the same tool for both data files and metadata definition files. The ODAM software can be deployed at multiple scales (local, intranet, internet), depending on the need and the target community. Guideline keywords : simplicity, flexibility, efficiency Give an open access to your data and make them ready to be mined - A data explorer as bonus : Test online with the FRIM dataset Documentation # Presentation : A presentation on the ODAM software, its aims and what can we do with it for what purposes. FAIR_and_DataLife_DJ_Oct2019.pdf Presentation : Part 1: How to best manage your data to make the most of it for your research Make your data great now Presentation : Part 2: How to ensure that open data works for research - Towards Linked Data Make your data great again Document : ODAM: Deployment and User's Guide ODAM - Deployment and User's Guide Document : Data Preparation Protocol for ODAM Compliance. protocols.io doi:10.17504/protocols.io.betcjeiw Document :How to install a VM embedding the ODAM software on Oracle VM VirtualBox doi:10.15454/C9LAEF , Portail Data INRAE, V1","title":"Getting started"},{"location":"getting_started/#odam-deployment-and-users-guide","text":"ODAM (Open Data for Access and Mining) is an Experiment Data Table Management System (EDTMS)","title":"ODAM: Deployment and User's Guide"},{"location":"getting_started/#background","text":"When generating data in an experiment involving several types of data from several analytical techniques, and this for the same samples, the task of being able to easily link these different data on the basis of sample identifiers is crucial. This is because the consistency of the data must be ensured throughout the experiment, so that it becomes unnecessary for each member to conduct a laborious investigation to find out who has the correct identifiers. Each time we plan to share data coming from a common experimental design, the classical challenges for fast using data by every partner are data storage and data access. We propose an approach for sharing project data all along its development phase, from the setup of the experimental schema up to the data acquisition from the various analyzes of samples, so that all data is readily available as soon as they are generated.","title":"Background"},{"location":"getting_started/#proposed-solution","text":"ODAM software is designed to manage experimental data tables in a quick and easy way for users. There is no need to develop a complex data model. Just complete the data with some structural metadata. These structural metadata will be used first to make full use of the data as soon as they are produced and formatted and then to annotate the dataset for later dissemination, either to project partners or more widely. The core idea in one shot The central idea which has been the founding idea of ODAM, is that data producers \"just\" have to drag and drop their data tables onto a storage space, which depending on the chosen infrastructure can be local (i.e. their PC, or a NAS) or remote (virtual disk space). So simply dropping data files (along with two additional metadata files) on the storage space allows users to access them through web services. This means there is no need for additional configuration on the server. ODAM proposes to meet certain needs typically encountered during the implementation of an experimental design in life science including several different analyses of the same sample. 1 - Data collecting and preparation The formatting of all the data and matching the data from the different analyses with their experimental context can be a long step. Tasks such as collecting and preparing data in order to combine several data sources require a lot of long, repetitive and tedious manipulations. Similarly, when modeling, subsets must be selected and then many scenarios with different parameters must be tested. 2 - Data sharing Enabling centralized management of identifiers (e.g. plants, crops, samples, etc.) so that they are unique and shared by all project members. Indeed, as each biological sample is most often aliquoted and then sent for analysis by different techniques, the data returned in tabular form must be able to be linked to the other data according to the identifiers of the samples Giving access to data for rapid use by each project member and this throughout the development phase, from the implementation of the experimental design to the acquisition of data from the various sample analyses, so that all data are readily available as soon as they are generated. 3 - Data publishing To be able to publish one's data without a colossal effort of formatting, and without the need for data archaeology. To be able to publish one's data according to the FAIR principles , at least the essentials To facilitate the reuse of data by providing structural metadata, thus avoiding that data consumers spend a disproportionate amount of time trying to understand the digital resources they need and devising specific ways to combine them. ODAM sofware suite allows experimental data tables to be widely accessible and fully reusable and this with minimal effort on the part of the data provider. Easily structure your data by adding structural metadata so that you can first exploit it locally yourself, before sharing it more widely just as easily. make research data locally or broadly accessible all along the project allow data to be selected then, downloadable by web API allow data and analysis to be visualized online Based on the following criteria: Centrally manage identifiers (plants, harvests, samples, ...) so that they are unique and shared by all Avoid the implementation of a complex data management system (requiring a data model) given that many changes can occur during the project. (possibility of new analysis, new measures or give up some others, ...) Facilitates the subsequent publication of data: either the data can serve to fill in an existing database or the data can be broadcast through a web-service approach with the associated metadata. For this work, we made the choice to keep the good old way of scientist to use worksheets, thus using the same tool for both data files and metadata definition files. The ODAM software can be deployed at multiple scales (local, intranet, internet), depending on the need and the target community. Guideline keywords : simplicity, flexibility, efficiency Give an open access to your data and make them ready to be mined - A data explorer as bonus : Test online with the FRIM dataset","title":"Proposed solution"},{"location":"getting_started/#documentation","text":"Presentation : A presentation on the ODAM software, its aims and what can we do with it for what purposes. FAIR_and_DataLife_DJ_Oct2019.pdf Presentation : Part 1: How to best manage your data to make the most of it for your research Make your data great now Presentation : Part 2: How to ensure that open data works for research - Towards Linked Data Make your data great again Document : ODAM: Deployment and User's Guide ODAM - Deployment and User's Guide Document : Data Preparation Protocol for ODAM Compliance. protocols.io doi:10.17504/protocols.io.betcjeiw Document :How to install a VM embedding the ODAM software on Oracle VM VirtualBox doi:10.15454/C9LAEF , Portail Data INRAE, V1","title":"Documentation"},{"location":"json-schema/","text":"ODAM: Deployment and User's Guide # ODAM data-package based on JSON-Schema # A data package is a simple container format based on JSON Schema specifications used to describe and package a collection of data. Defining an explicit schema for structural metadata allows machines to better interpret the data for reuse. Thus, when disseminating data, a file named datapackage.json by convention can be added to the collection of your data files. This datapackage.json file contains all structural metadata along with unambiguous definitions of all internal elements (e.g. column definitions, units of measurement), through links to accessible (standard) definitions. The datapackage.json file can be generated directly from the ODAM API by specifying ' /datapackage ' at the end of the request. By default, the reference to the data files is relative. To have a URL as reference for the data files, it is necessary to add at the end of the request ' ?links=1 ' ODAM data package schema is very close to the Frictionless Data framework. odam-data-package.json : JSON Schema for ODAM data package odam-data-resource.json : JSON Schema for ODAM data resource ODAM data-package on github https://github.com/djacob65/odam-datapackage Frictionless Data Specifications http://specs.frictionlessdata.io/ https://github.com/frictionlessdata/specs/tree/master/schemas json_validate: Validate a json file https://rdrr.io/cran/jsonvalidate/man/json_validate.html Example of a session under R using a data package # library ( httr ) library ( jsonvalidate ) library ( jsonlite ) # Get the ODAM data package schema response <- GET ( 'https://inrae.github.io/ODAM/json-schema/odam-data-package.json' , config ( sslversion = 6 , ssl_verifypeer = 1 )) schema <- rawToChar ( response $ content ) # Get structural metadata information in datapackage format (json) # for the 'frim1' dataset directly from an ODAM repository # (located on https://pmb-bordeaux.fr) # As the option links is set to 1, we will have the absolute reference # for data files (see below) response <- GET ( 'https://pmb-bordeaux.fr/getdata/json/frim1/datapackage?links=1' , config ( sslversion = 6 , ssl_verifypeer = 1 )) json <- rawToChar ( response $ content ) # Validate the JSON against the ODAM data package schema jsonvalidate :: json_validate ( json , schema ) [1] TRUE Code # Parse the JSON object to a data.frame metadata <- fromJSON ( json ) # List some metadata about the dataset metadata $ resources[ c ( \"name\" , \"title\" , \"identifier\" , \"obtainedFrom\" , \"joinkey\" ) ] Output name title identifier obtainedFrom joinkey 1 plants Plant features PlantID <NA> <NA> 2 samples Sample features SampleID plants PlantID 3 aliquots Aliquots features AliquotID samples SampleID 4 cellwall_metabo Cell wall Compound quantifications AliquotID aliquots AliquotID 5 cellwall_metaboFW Cell Wall Compound quantifications (FW) AliquotID aliquots AliquotID 6 activome Activome Features AliquotID aliquots AliquotID 7 pools Pools of remaining pools PoolID samples SampleID 8 qMS_metabo MS Compounds quantification PoolID pools PoolID 9 qNMR_metabo NMR Compounds quantification PoolID pools PoolID 10 plato_hexosesP Hexoses Phosphate AliquotID aliquots AliquotID 11 lipids_AG Lipids AG AliquotID aliquots AliquotID 12 AminoAcid Amino Acids AliquotID aliquots AliquotID Code # List the absolute reference for data files metadata $ resources[ \"path\" ] Output path 1 https://pmb-bordeaux.fr/getdata/tsv/frim1/plants 2 https://pmb-bordeaux.fr/getdata/tsv/frim1/samples 3 https://pmb-bordeaux.fr/getdata/tsv/frim1/aliquots 4 https://pmb-bordeaux.fr/getdata/tsv/frim1/cellwall_metabo 5 https://pmb-bordeaux.fr/getdata/tsv/frim1/cellwall_metaboFW 6 https://pmb-bordeaux.fr/getdata/tsv/frim1/activome 7 https://pmb-bordeaux.fr/getdata/tsv/frim1/pools 8 https://pmb-bordeaux.fr/getdata/tsv/frim1/qMS_metabo 9 https://pmb-bordeaux.fr/getdata/tsv/frim1/qNMR_metabo 10 https://pmb-bordeaux.fr/getdata/tsv/frim1/plato_hexosesP 11 https://pmb-bordeaux.fr/getdata/tsv/frim1/lipids_AG 12 https://pmb-bordeaux.fr/getdata/tsv/frim1/AminoAcid Code # Read the 'samples' data file - index=2 index <- 2 M <- read.table ( url ( metadata $ resources[ \"path\" ] $ path[index] ), header = metadata $ resources $ dialect $ header[index] , sep = metadata $ resources $ dialect $ delimiter[index] ) # Display an extract M[1 : 10 , ] Output SampleID PlantID Truss DevStage FruitAge HarvestDate HarvestHour FruitPosition FruitDiameter FruitHeight FruitFW FruitDW DW 1 1 A26 T5 FF.01 08DPA 40379 0.5 2 NA NA 0.72 0.090216 NA 2 1 C2 T5 FF.01 08DPA 40379 0.5 3 NA NA 0.56 0.070168 NA 3 1 D15 T5 FF.01 08DPA 40379 0.5 4 NA NA 0.78 0.097734 NA 4 1 E19 T5 FF.01 08DPA 40379 0.5 4 NA NA 0.66 0.082698 NA 5 1 E34 T5 FF.01 08DPA 40379 0.5 3 NA NA 0.7 0.087710 NA 6 1 E38 T5 FF.01 08DPA 40379 0.5 3 NA NA 0.7 0.087710 NA 7 1 H29 T5 FF.01 08DPA 40379 0.5 5 NA NA 1.24 0.155372 NA 8 1 H34 T5 FF.01 08DPA 40379 0.5 4 NA NA 0.86 0.107758 NA 9 1 H52 T5 FF.01 08DPA 40379 0.5 5 NA NA 0.77 0.096481 NA 10 1 H61 T5 FF.01 08DPA 40379 0.5 5 NA NA 0.56 0.070168 NA Code # Get the list of data subsets that were obtained from the 'samples' index <- 2 subsets <- metadata $ resources $ schema $ foreignKey[[index]] $ reference[ , 1 ] if ( ! is.null ( subsets ) ) metadata $ resources[ metadata $ resources $ name %in% subsets , c ( \"name\" , \"title\" , \"identifier\" , \"obtainedFrom\" ) ] Output name title identifier obtainedFrom 3 aliquots Aliquots features AliquotID samples 7 pools Pools of remaining pools PoolID samples Code # Get the list of data subsets that were obtained from the 'aliquots' index <- 3 subsets <- metadata $ resources $ schema $ foreignKey[[index]] $ reference[ , 1 ] if ( ! is.null ( subsets ) ) metadata $ resources[ metadata $ resources $ name %in% subsets , c ( \"name\" , \"title\" , \"identifier\" , \"obtainedFrom\" ) ] Output name title identifier obtainedFrom 4 cellwall_metabo Cell wall Compound quantifications AliquotID aliquots 5 cellwall_metaboFW Cell Wall Compound quantifications (FW) AliquotID aliquots 6 activome Activome Features AliquotID aliquots 10 plato_hexosesP Hexoses Phosphate AliquotID aliquots 11 lipids_AG Lipids AG AliquotID aliquots 12 AminoAcid Amino Acids AliquotID aliquots","title":"json-schema"},{"location":"json-schema/#odam-deployment-and-users-guide","text":"","title":"ODAM: Deployment and User's Guide"},{"location":"json-schema/#odam-data-package-based-on-json-schema","text":"A data package is a simple container format based on JSON Schema specifications used to describe and package a collection of data. Defining an explicit schema for structural metadata allows machines to better interpret the data for reuse. Thus, when disseminating data, a file named datapackage.json by convention can be added to the collection of your data files. This datapackage.json file contains all structural metadata along with unambiguous definitions of all internal elements (e.g. column definitions, units of measurement), through links to accessible (standard) definitions. The datapackage.json file can be generated directly from the ODAM API by specifying ' /datapackage ' at the end of the request. By default, the reference to the data files is relative. To have a URL as reference for the data files, it is necessary to add at the end of the request ' ?links=1 ' ODAM data package schema is very close to the Frictionless Data framework. odam-data-package.json : JSON Schema for ODAM data package odam-data-resource.json : JSON Schema for ODAM data resource ODAM data-package on github https://github.com/djacob65/odam-datapackage Frictionless Data Specifications http://specs.frictionlessdata.io/ https://github.com/frictionlessdata/specs/tree/master/schemas json_validate: Validate a json file https://rdrr.io/cran/jsonvalidate/man/json_validate.html","title":"ODAM data-package based on JSON-Schema"},{"location":"json-schema/#example-of-a-session-under-r-using-a-data-package","text":"library ( httr ) library ( jsonvalidate ) library ( jsonlite ) # Get the ODAM data package schema response <- GET ( 'https://inrae.github.io/ODAM/json-schema/odam-data-package.json' , config ( sslversion = 6 , ssl_verifypeer = 1 )) schema <- rawToChar ( response $ content ) # Get structural metadata information in datapackage format (json) # for the 'frim1' dataset directly from an ODAM repository # (located on https://pmb-bordeaux.fr) # As the option links is set to 1, we will have the absolute reference # for data files (see below) response <- GET ( 'https://pmb-bordeaux.fr/getdata/json/frim1/datapackage?links=1' , config ( sslversion = 6 , ssl_verifypeer = 1 )) json <- rawToChar ( response $ content ) # Validate the JSON against the ODAM data package schema jsonvalidate :: json_validate ( json , schema ) [1] TRUE Code # Parse the JSON object to a data.frame metadata <- fromJSON ( json ) # List some metadata about the dataset metadata $ resources[ c ( \"name\" , \"title\" , \"identifier\" , \"obtainedFrom\" , \"joinkey\" ) ] Output name title identifier obtainedFrom joinkey 1 plants Plant features PlantID <NA> <NA> 2 samples Sample features SampleID plants PlantID 3 aliquots Aliquots features AliquotID samples SampleID 4 cellwall_metabo Cell wall Compound quantifications AliquotID aliquots AliquotID 5 cellwall_metaboFW Cell Wall Compound quantifications (FW) AliquotID aliquots AliquotID 6 activome Activome Features AliquotID aliquots AliquotID 7 pools Pools of remaining pools PoolID samples SampleID 8 qMS_metabo MS Compounds quantification PoolID pools PoolID 9 qNMR_metabo NMR Compounds quantification PoolID pools PoolID 10 plato_hexosesP Hexoses Phosphate AliquotID aliquots AliquotID 11 lipids_AG Lipids AG AliquotID aliquots AliquotID 12 AminoAcid Amino Acids AliquotID aliquots AliquotID Code # List the absolute reference for data files metadata $ resources[ \"path\" ] Output path 1 https://pmb-bordeaux.fr/getdata/tsv/frim1/plants 2 https://pmb-bordeaux.fr/getdata/tsv/frim1/samples 3 https://pmb-bordeaux.fr/getdata/tsv/frim1/aliquots 4 https://pmb-bordeaux.fr/getdata/tsv/frim1/cellwall_metabo 5 https://pmb-bordeaux.fr/getdata/tsv/frim1/cellwall_metaboFW 6 https://pmb-bordeaux.fr/getdata/tsv/frim1/activome 7 https://pmb-bordeaux.fr/getdata/tsv/frim1/pools 8 https://pmb-bordeaux.fr/getdata/tsv/frim1/qMS_metabo 9 https://pmb-bordeaux.fr/getdata/tsv/frim1/qNMR_metabo 10 https://pmb-bordeaux.fr/getdata/tsv/frim1/plato_hexosesP 11 https://pmb-bordeaux.fr/getdata/tsv/frim1/lipids_AG 12 https://pmb-bordeaux.fr/getdata/tsv/frim1/AminoAcid Code # Read the 'samples' data file - index=2 index <- 2 M <- read.table ( url ( metadata $ resources[ \"path\" ] $ path[index] ), header = metadata $ resources $ dialect $ header[index] , sep = metadata $ resources $ dialect $ delimiter[index] ) # Display an extract M[1 : 10 , ] Output SampleID PlantID Truss DevStage FruitAge HarvestDate HarvestHour FruitPosition FruitDiameter FruitHeight FruitFW FruitDW DW 1 1 A26 T5 FF.01 08DPA 40379 0.5 2 NA NA 0.72 0.090216 NA 2 1 C2 T5 FF.01 08DPA 40379 0.5 3 NA NA 0.56 0.070168 NA 3 1 D15 T5 FF.01 08DPA 40379 0.5 4 NA NA 0.78 0.097734 NA 4 1 E19 T5 FF.01 08DPA 40379 0.5 4 NA NA 0.66 0.082698 NA 5 1 E34 T5 FF.01 08DPA 40379 0.5 3 NA NA 0.7 0.087710 NA 6 1 E38 T5 FF.01 08DPA 40379 0.5 3 NA NA 0.7 0.087710 NA 7 1 H29 T5 FF.01 08DPA 40379 0.5 5 NA NA 1.24 0.155372 NA 8 1 H34 T5 FF.01 08DPA 40379 0.5 4 NA NA 0.86 0.107758 NA 9 1 H52 T5 FF.01 08DPA 40379 0.5 5 NA NA 0.77 0.096481 NA 10 1 H61 T5 FF.01 08DPA 40379 0.5 5 NA NA 0.56 0.070168 NA Code # Get the list of data subsets that were obtained from the 'samples' index <- 2 subsets <- metadata $ resources $ schema $ foreignKey[[index]] $ reference[ , 1 ] if ( ! is.null ( subsets ) ) metadata $ resources[ metadata $ resources $ name %in% subsets , c ( \"name\" , \"title\" , \"identifier\" , \"obtainedFrom\" ) ] Output name title identifier obtainedFrom 3 aliquots Aliquots features AliquotID samples 7 pools Pools of remaining pools PoolID samples Code # Get the list of data subsets that were obtained from the 'aliquots' index <- 3 subsets <- metadata $ resources $ schema $ foreignKey[[index]] $ reference[ , 1 ] if ( ! is.null ( subsets ) ) metadata $ resources[ metadata $ resources $ name %in% subsets , c ( \"name\" , \"title\" , \"identifier\" , \"obtainedFrom\" ) ] Output name title identifier obtainedFrom 4 cellwall_metabo Cell wall Compound quantifications AliquotID aliquots 5 cellwall_metaboFW Cell Wall Compound quantifications (FW) AliquotID aliquots 6 activome Activome Features AliquotID aliquots 10 plato_hexosesP Hexoses Phosphate AliquotID aliquots 11 lipids_AG Lipids AG AliquotID aliquots 12 AminoAcid Amino Acids AliquotID aliquots","title":"Example of a session under R using a data package"},{"location":"tests/","text":"ODAM: Deployment and User's Guide # First Header Second Header Third Header Left Center Right Left Center Right Data Preparation Protocol for ODAM Compliance. protocols.io https://dx.doi.org/10.17504/protocols.io.betcjeiw Data Preparation Protocol for ODAM Compliance. protocols.io https://dx.doi.org/10.17504/protocols.io.betcjeiw Field | Description | Examples | Format of the retrieved data; possible values are: 'xml', \u2018json\u2019 or \u2018tsv' | tsv | Short name (tag) of your dataset | frim1 | Short name of a data subset | samples | Name of an attribute entry (defined by the user in the a_attribute file (column \u2018entry\u2019) | sampleid | Name of the attribute category; (assigned by the user in the a_attribute file (column \u2018category\u2019). Possible values are: \u2018identifier\u2019, \u2018factor\u2019, \u2018qualitative\u2019, \u2018quantitative\u2019 | quantitative ( ) | Set of data subsets by merging all the subsets with lower rank than the specified subset and following the pathway defined by the \"is_part_of\" links. | (samples) <=> plants + samples | Exact value of the desired entry or category | 1 (subset) Factor (category)","title":"My Document"},{"location":"tests/#odam-deployment-and-users-guide","text":"First Header Second Header Third Header Left Center Right Left Center Right Data Preparation Protocol for ODAM Compliance. protocols.io https://dx.doi.org/10.17504/protocols.io.betcjeiw Data Preparation Protocol for ODAM Compliance. protocols.io https://dx.doi.org/10.17504/protocols.io.betcjeiw Field | Description | Examples | Format of the retrieved data; possible values are: 'xml', \u2018json\u2019 or \u2018tsv' | tsv | Short name (tag) of your dataset | frim1 | Short name of a data subset | samples | Name of an attribute entry (defined by the user in the a_attribute file (column \u2018entry\u2019) | sampleid | Name of the attribute category; (assigned by the user in the a_attribute file (column \u2018category\u2019). Possible values are: \u2018identifier\u2019, \u2018factor\u2019, \u2018qualitative\u2019, \u2018quantitative\u2019 | quantitative ( ) | Set of data subsets by merging all the subsets with lower rank than the specified subset and following the pathway defined by the \"is_part_of\" links. | (samples) <=> plants + samples | Exact value of the desired entry or category | 1 (subset) Factor (category)","title":"ODAM: Deployment and User's Guide"},{"location":"fair/fair-frim/","text":"ODAM: Deployment and User's Guide # FAIR grids applied on FRIM dataset # Three FAIR grids avery different from each other. 1- 5 \u2605 Data Rating Tool From OZONOME , it aims to carry out an evaluation based on the FAIR principles as defined by Willkinson et al (1). The main output is a global rating, indicating the global FAIRness of the dataset. It provides implementations of the FORCE 11 FAIR data principles . 2 - FDMM (FAIR Data Maturity Model) (2) FDMM is a recognized and endorsed working group within RDA (Research Data Alliance). They produce a document that describes a maturity model for FAIR assessment with assessment indicators, priorities and evaluation methods, useful for the normalisation of assessment approaches to enable comparison of their results. 3 - SHARC (Sharing Rewards and Credit) (3) SHARC is a recognized and endorsed working group within RDA (Research Data Alliance). They produce a document that allows assessing FAIRness of projects and related human processes by either external evaluators or the researchers themselves, implying to implement simple FAIRness assessment in various communities and identify procedures and training that must be deployed and adapted to their practices and level of understanding. Results # 5 \u2605 Data Rating Tool https://oznome.csiro.au/5star/?view=5ec2a9654d0983adde57a21e FDMM (FAIR Data Maturity Model) https://drive.google.com/file/d/1a520Cbu8bryEeZIPI3h1l6zkaO7MZ39-/view?usp=sharing SHARC (Sharing Rewards and Credit) https://drive.google.com/file/d/1uif-jy9QBno_WPnpGL14LFpDzL366tMH/view?usp=sharing Synthesis of FAIR evaluation grids applied to the Frim dataset The Fair Data Maturity Model (FDMM) document (A) describes a maturity model for the FAIR assessment with indicators, priorities and assessment methods, which are useful for standardizing assessment approaches in order to allow comparison of their results. Whereas the FAIR SHARC (SHAring Rewards and Credit) (B) document allows the fairness of projects and associated human processes to be assessed, either by external evaluators or by the researchers themselves. Therefore, these grids cannot be compared with each other, but rather complement each other. Summary table of essential FAIR criteria based on force11.org, applied to the Frim dataset References # Wilkinson, M., Dumontier, M., Aalbersberg, I. et al. (2016) The FAIR Guiding Principles for scientific data management and stewardship. Sci Data 3, 160018. doi:10.1038/sdata.2016.18 RDA FAIR Data Maturity Model Working Group (2020). FAIR Data Maturity Model: specification and guidelines. Research Data Alliance. DOI: 10.15497/RDA00045 Romain David, Laurence Mabile, Alison Specht, Stryeck, Sarah, Mogens Thomsen, et al. FAIRness Literacy: the Achilles' Heel of applying FAIR Principles. 2020. https://hal.archives-ouvertes.fr/hal-02483307","title":"FAIR_on_frim"},{"location":"fair/fair-frim/#odam-deployment-and-users-guide","text":"","title":"ODAM: Deployment and User's Guide"},{"location":"fair/fair-frim/#fair-grids-applied-on-frim-dataset","text":"Three FAIR grids avery different from each other. 1- 5 \u2605 Data Rating Tool From OZONOME , it aims to carry out an evaluation based on the FAIR principles as defined by Willkinson et al (1). The main output is a global rating, indicating the global FAIRness of the dataset. It provides implementations of the FORCE 11 FAIR data principles . 2 - FDMM (FAIR Data Maturity Model) (2) FDMM is a recognized and endorsed working group within RDA (Research Data Alliance). They produce a document that describes a maturity model for FAIR assessment with assessment indicators, priorities and evaluation methods, useful for the normalisation of assessment approaches to enable comparison of their results. 3 - SHARC (Sharing Rewards and Credit) (3) SHARC is a recognized and endorsed working group within RDA (Research Data Alliance). They produce a document that allows assessing FAIRness of projects and related human processes by either external evaluators or the researchers themselves, implying to implement simple FAIRness assessment in various communities and identify procedures and training that must be deployed and adapted to their practices and level of understanding.","title":"FAIR grids applied on FRIM dataset"},{"location":"fair/fair-frim/#results","text":"5 \u2605 Data Rating Tool https://oznome.csiro.au/5star/?view=5ec2a9654d0983adde57a21e FDMM (FAIR Data Maturity Model) https://drive.google.com/file/d/1a520Cbu8bryEeZIPI3h1l6zkaO7MZ39-/view?usp=sharing SHARC (Sharing Rewards and Credit) https://drive.google.com/file/d/1uif-jy9QBno_WPnpGL14LFpDzL366tMH/view?usp=sharing Synthesis of FAIR evaluation grids applied to the Frim dataset The Fair Data Maturity Model (FDMM) document (A) describes a maturity model for the FAIR assessment with indicators, priorities and assessment methods, which are useful for standardizing assessment approaches in order to allow comparison of their results. Whereas the FAIR SHARC (SHAring Rewards and Credit) (B) document allows the fairness of projects and associated human processes to be assessed, either by external evaluators or by the researchers themselves. Therefore, these grids cannot be compared with each other, but rather complement each other. Summary table of essential FAIR criteria based on force11.org, applied to the Frim dataset","title":"Results"},{"location":"fair/fair-frim/#references","text":"Wilkinson, M., Dumontier, M., Aalbersberg, I. et al. (2016) The FAIR Guiding Principles for scientific data management and stewardship. Sci Data 3, 160018. doi:10.1038/sdata.2016.18 RDA FAIR Data Maturity Model Working Group (2020). FAIR Data Maturity Model: specification and guidelines. Research Data Alliance. DOI: 10.15497/RDA00045 Romain David, Laurence Mabile, Alison Specht, Stryeck, Sarah, Mogens Thomsen, et al. FAIRness Literacy: the Achilles' Heel of applying FAIR Principles. 2020. https://hal.archives-ouvertes.fr/hal-02483307","title":"References"},{"location":"json-schema/odam-data-package/","text":"{ \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"https://inrae.github.io/ODAM/json-schema/odam-data-package.json\" , \"title\" : \"odam-data-package\" , \"description\" : \"Description of an ODAM data package\" , \"type\" : \"object\" , \"definitions\" : { \"profile\" : { \"title\" : \"odam-data-package\" , \"description\" : \"odam-data-package profile is an extension of the tabular-data-package profile\" , \"type\" : \"string\" }, \"path\" : { \"title\" : \"Path\" , \"description\" : \"A fully qualified URL, or a POSIX file path..\" , \"type\" : \"string\" , \"pattern\" : \"^(?=^[^./~])(^((?!\\\\.{2}).)*$).*$\" , \"context\" : \"Implementations need to negotiate the type of path provided, and dereference the data accordingly.\" }, \"name\" : { \"title\" : \"Name\" , \"description\" : \"An identifier string. Lower case characters with `_` are allowed.\" , \"type\" : \"string\" , \"pattern\" : \"^([a-zA-Z0-9_])+$\" , \"context\" : \"This is ideally a url-usable and human-readable name. Name `SHOULD` be invariant, meaning it `SHOULD NOT` change when its parent descriptor is updated.\" }, \"title\" : { \"title\" : \"Title\" , \"description\" : \"A human-readable title.\" , \"type\" : \"string\" }, \"keywords\" : { \"title\" : \"Keywords\" , \"description\" : \"A list of keywords that describe this package.\" , \"type\" : \"array\" , \"minItems\" : 1 , \"items\" : { \"type\" : \"string\" } }, \"license\" : { \"title\" : \"License\" , \"description\" : \"A license for this descriptor.\" , \"type\" : \"object\" , \"properties\" : { \"name\" : { \"title\" : \"Open Definition license identifier\" , \"description\" : \"MUST be an Open Definition license identifier, see http://licenses.opendefinition.org/\" , \"type\" : \"string\" , \"pattern\" : \"^([-a-zA-Z0-9._])+$\" }, \"path\" : { \"$ref\" : \"#/definitions/path\" }, \"title\" : { \"$ref\" : \"#/definitions/title\" } }, \"context\" : \"Use of this property does not imply that the person was the original creator of, or a contributor to, the data in the descriptor, but refers to the composition of the descriptor itself.\" }, \"licenses\" : { \"title\" : \"Licenses\" , \"description\" : \"The license(s) under which this package is published.\" , \"type\" : \"array\" , \"minItems\" : 1 , \"items\" : { \"$ref\" : \"#/definitions/license\" }, \"context\" : \"This property is not legally binding and does not guarantee that the package is licensed under the terms defined herein.\" }, \"tabularDataResources\" : { \"title\" : \"Tabular Data Resources\" , \"description\" : \"An `array` of Tabular Data Resource objects, each compliant with the [Tabular Data Resource](/tabular-data-resource/) specification.\" , \"type\" : \"array\" , \"minItems\" : 1 , \"items\" : { \"$ref\" : \"https://inrae.github.io/ODAM/json-schema/odam-data-resource.json\" } } }, \"properties\" : { \"profile\" : { \"$ref\" : \"#/definitions/profile\" }, \"name\" : { \"$ref\" : \"#/definitions/name\" }, \"datapackage_version\" : { \"type\" : \"string\" , \"pattern\" : \"^([0-9.])+$\" }, \"keywords\" : { \"$ref\" : \"#/definitions/keywords\" }, \"licenses\" : { \"$ref\" : \"#/definitions/licenses\" }, \"resources\" : { \"$ref\" : \"#/definitions/tabularDataResources\" } }, \"required\" : [ \"profile\" , \"name\" , \"licenses\" , \"resources\" ] }","title":"Odam data package"},{"location":"json-schema/odam-data-resource/","text":"{ \"$schema\" : \"http://json-schema.org/draft-07/schema#\" , \"$id\" : \"https://inrae.github.io/ODAM/json-schema/odam-data-resource.json\" , \"title\" : \"odam-data-resource\" , \"description\" : \"Description of an ODAM data resource\" , \"type\" : \"object\" , \"definitions\" : { \"profile\" : { \"title\" : \"odam-data-resource\" , \"description\" : \"odam-data-resource profile is an extension of the tabular data resource profile\" , \"type\" : \"string\" }, \"name\" : { \"title\" : \"Name\" , \"description\" : \"An identifier string. Lower case characters with `_` are allowed.\" , \"type\" : \"string\" , \"pattern\" : \"^([a-zA-Z0-9_])+$\" , \"context\" : \"This is ideally a url-usable and human-readable name. Name `SHOULD` be invariant, meaning it `SHOULD NOT` change when its parent descriptor is updated.\" }, \"title\" : { \"title\" : \"Title\" , \"description\" : \"A human-readable title.\" , \"type\" : \"string\" }, \"description\" : { \"title\" : \"Description\" , \"description\" : \"A text description. Markdown is encouraged.\" , \"type\" : \"string\" }, \"path\" : { \"title\" : \"Path\" , \"description\" : \"A fully qualified URL, or a POSIX file path..\" , \"type\" : \"string\" , \"pattern\" : \"^(?=^[^./~])(^((?!\\\\.{2}).)*$).*$\" , \"context\" : \"Implementations need to negotiate the type of path provided, and dereference the data accordingly.\" }, \"anyTermId\" : { \"title\" : \"CV Term id\" , \"description\" : \"URL of the controlled vocabulary\" , \"type\" : \"string\" }, \"anyTermName\" : { \"title\" : \"CV Term Name\" , \"description\" : \"Short description of the controlled vocabulary\" , \"type\" : \"string\" }, \"csvDialect\" : { \"title\" : \"CSV Dialect\" , \"description\" : \"The CSV dialect descriptor.\" , \"required\" : [ \"delimiter\" , \"doubleQuote\" ], \"properties\" : { \"csvddfVersion\" : { \"$ref\" : \"#/definitions/csvddfVersion\" }, \"delimiter\" : { \"$ref\" : \"#/definitions/delimiter\" }, \"doubleQuote\" : { \"$ref\" : \"#/definitions/doubleQuote\" }, \"lineTerminator\" : { \"$ref\" : \"#/definitions/lineTerminator\" }, \"quoteChar\" : { \"$ref\" : \"#/definitions/quoteChar\" }, \"escapeChar\" : { \"$ref\" : \"#/definitions/escapeChar\" }, \"skipInitialSpace\" : { \"$ref\" : \"#/definitions/skipInitialSpace\" }, \"header\" : { \"$ref\" : \"#/definitions/header\" }, \"commentChar\" : { \"$ref\" : \"#/definitions/commentChar\" }, \"caseSensitiveHeader\" : { \"$ref\" : \"#/definitions/caseSensitiveHeader\" } } }, \"csvddfVersion\" : { \"title\" : \"CSV Dialect schema version\" , \"description\" : \"A number to indicate the schema version of CSV Dialect. Version 1.0 was named CSV Dialect Description Format and used different field names.\" , \"type\" : \"number\" , \"default\" : 1.2 }, \"delimiter\" : { \"title\" : \"Delimiter\" , \"description\" : \"A character sequence to use as the field separator.\" , \"type\" : \"string\" , \"default\" : \",\" }, \"doubleQuote\" : { \"title\" : \"Double Quote\" , \"description\" : \"Specifies the handling of quotes inside fields.\" , \"context\" : \"If Double Quote is set to true, two consecutive quotes must be interpreted as one.\" , \"type\" : \"boolean\" , \"default\" : true }, \"lineTerminator\" : { \"title\" : \"Line Terminator\" , \"description\" : \"Specifies the character sequence that must be used to terminate rows.\" , \"type\" : \"string\" , \"default\" : \"\\n\" }, \"quoteChar\" : { \"title\" : \"Quote Character\" , \"description\" : \"Specifies a one-character string to use as the quoting character.\" , \"type\" : \"string\" , \"default\" : \"\\\"\" }, \"escapeChar\" : { \"title\" : \"Escape Character\" , \"description\" : \"Specifies a one-character string to use as the escape character.\" , \"type\" : \"string\" }, \"skipInitialSpace\" : { \"title\" : \"Skip Initial Space\" , \"description\" : \"Specifies the interpretation of whitespace immediately following a delimiter. If false, whitespace immediately after a delimiter should be treated as part of the subsequent field.\" , \"type\" : \"boolean\" , \"default\" : true }, \"header\" : { \"title\" : \"Header\" , \"description\" : \"Specifies if the file includes a header row, always as the first row in the file.\" , \"type\" : \"boolean\" , \"default\" : true }, \"commentChar\" : { \"title\" : \"Comment Character\" , \"description\" : \"Specifies a character sequence causing the rest of the line after it to be ignored.\" , \"type\" : \"string\" }, \"caseSensitiveHeader\" : { \"title\" : \"Case Sensitive Header\" , \"description\" : \"Specifies if the case of headers is meaningful.\" , \"context\" : \"Use of case in source CSV files is not always an intentional decision. For example, should \\\"CAT\\\" and \\\"Cat\\\" be considered to have the same meaning.\" , \"type\" : \"boolean\" , \"default\" : false }, \"format\" : { \"title\" : \"Format\" , \"description\" : \"The file format of this resource.\" , \"context\" : \"`csv`, `xls`, `json` are examples of common formats.\" , \"type\" : \"string\" }, \"mediatype\" : { \"title\" : \"Media Type\" , \"description\" : \"The media type of this resource. Can be any valid media type listed with [IANA](https://www.iana.org/assignments/media-types/media-types.xhtml).\" , \"type\" : \"string\" , \"pattern\" : \"^(.+)/(.+)$\" }, \"encoding\" : { \"title\" : \"Encoding\" , \"description\" : \"The file encoding of this resource.\" , \"type\" : \"string\" , \"default\" : \"utf-8\" }, \"tableSchema\" : { \"title\" : \"Table Schema\" , \"description\" : \"A Table Schema for this resource, compliant with the [Table Schema](/tableschema/) specification.\" , \"type\" : \"object\" , \"required\" : [ \"fields\" , \"categories\" ], \"properties\" : { \"fields\" : { \"type\" : \"array\" , \"minItems\" : 1 , \"items\" : { \"$ref\" : \"#/definitions/tableSchemaField\" }, \"description\" : \"An `array` of Table Schema Field objects.\" }, \"primaryKey\" : { \"$ref\" : \"#/definitions/tableSchemaPrimaryKey\" }, \"foreignKeys\" : { \"type\" : \"array\" , \"minItems\" : 1 , \"items\" : { \"$ref\" : \"#/definitions/tableSchemaForeignKey\" } }, \"categories\" : { \"type\" : \"array\" , \"minItems\" : 1 , \"items\" : { \"$ref\" : \"#/definitions/tableSchemaCategory\" }, \"description\" : \"An `array` of Table Schema Category objects.\" } } }, \"tableSchemaField\" : { \"title\" : \"Table Schema Field\" , \"type\" : \"object\" , \"required\" : [ \"name\" , \"type\" , \"title\" ], \"properties\" : { \"name\" : { \"$ref\" : \"#/definitions/name\" }, \"type\" : { \"type\" : \"string\" , \"enum\" : [ \"number\" , \"string\" ] }, \"title\" : { \"$ref\" : \"#/definitions/title\" }, \"unit\" : { \"type\" : \"string\" }, \"cv_term_id\" : { \"$ref\" : \"#/definitions/anyTermId\" }, \"cv_term_name\" : { \"$ref\" : \"#/definitions/anyTermName\" }, \"constraints\" : { \"title\" : \"Constraints\" , \"description\" : \"The following constraints are supported for `string` fields.\" , \"type\" : \"object\" , \"properties\" : { \"required\" : { \"type\" : \"boolean\" , \"description\" : \"Indicates whether a property must have a value for each instance.\" , \"context\" : \"An empty string is considered to be a missing value.\" }, \"unique\" : { \"type\" : \"boolean\" , \"description\" : \"When `true`, each value for the property `MUST` be unique.\" } } } } }, \"tableSchemaPrimaryKey\" : { \"oneOf\" : [ { \"type\" : \"array\" , \"minItems\" : 1 , \"uniqueItems\" : true , \"items\" : { \"type\" : \"string\" } }, { \"type\" : \"string\" } ], \"description\" : \"A primary key is a field name or an array of field names, whose values `MUST` uniquely identify each row in the table.\" }, \"tableSchemaForeignKey\" : { \"title\" : \"Table Schema Foreign Key\" , \"description\" : \"Table Schema Foreign Key\" , \"type\" : \"object\" , \"required\" : [ \"fields\" , \"reference\" ], \"properties\" : { \"fields\" : { \"type\" : \"string\" , \"description\" : \"Fields that make up the primary key.\" }, \"reference\" : { \"type\" : \"object\" , \"required\" : [ \"resource\" , \"fields\" ], \"properties\" : { \"resource\" : { \"type\" : \"string\" , \"default\" : \"\" }, \"fields\" : { \"type\" : \"string\" } } } } }, \"tableSchemaCategory\" : { \"title\" : \"Table Schema Category\" , \"type\" : \"object\" , \"properties\" : { \"name\" : { \"type\" : \"string\" , \"enum\" : [ \"identifier\" , \"factor\" , \"quantitative\" , \"qualitative\" ] }, \"fields\" : { \"type\" : \"array\" } } }, \"tableSchemaMissingValues\" : { \"type\" : \"array\" , \"items\" : { \"type\" : \"string\" }, \"default\" : [ \"\" ] } }, \"properties\" : { \"path\" : { \"$ref\" : \"#/definitions/path\" }, \"profile\" : { \"$ref\" : \"#/definitions/profile\" }, \"name\" : { \"$ref\" : \"#/definitions/name\" }, \"title\" : { \"$ref\" : \"#/definitions/title\" }, \"identifier\" : { \"description\" : \"name of the identifier field (column name). i.e same as primaryKey\" , \"type\" : \"string\" }, \"obtainedFrom\" : { \"description\" : \"name of the file \" , \"type\" : \"string\" }, \"joinkey\" : { \"description\" : \"name of the identifier field (column name) that serves to link with its father file i.e same as foreignKey\" , \"type\" : \"string\" }, \"cv_term_id\" : { \"$ref\" : \"#/definitions/anyTermId\" }, \"cv_term_name\" : { \"$ref\" : \"#/definitions/anyTermName\" }, \"schema\" : { \"$ref\" : \"#/definitions/tableSchema\" }, \"dialect\" : { \"$ref\" : \"#/definitions/csvDialect\" }, \"encoding\" : { \"$ref\" : \"#/definitions/encoding\" }, \"format\" : { \"$ref\" : \"#/definitions/format\" }, \"mediatype\" : { \"$ref\" : \"#/definitions/mediatype\" }, \"missingValues\" : { \"$ref\" : \"#/definitions/tableSchemaMissingValues\" } }, \"required\" : [ \"path\" , \"name\" , \"title\" , \"identifier\" , \"schema\" , \"dialect\" , \"format\" ] }","title":"Odam data resource"}]}